{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829eeee5-b288-4240-b668-187f7be574e8",
   "metadata": {
    "id": "829eeee5-b288-4240-b668-187f7be574e8"
   },
   "source": [
    "# Homework 2\n",
    "\n",
    "In this homework, we will go through the Hough transform.\n",
    "\n",
    "*This homework was adapted from Stanford CS131.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f67bb-bc9e-457b-8df7-e7ea3200c097",
   "metadata": {
    "id": "5e5f67bb-bc9e-457b-8df7-e7ea3200c097"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872849b4-307c-484f-80b8-e963442b26d6",
   "metadata": {
    "id": "872849b4-307c-484f-80b8-e963442b26d6"
   },
   "source": [
    "### **Step 1**\n",
    "\n",
    "First, run the cells below to clone the `CS131_release` [repo](https://github.com/StanfordVL/CS131_release) and `cd` into the correct directory in order to access some necessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d7744-dbf3-4b5b-9800-665e5763dbaf",
   "metadata": {
    "id": "616d7744-dbf3-4b5b-9800-665e5763dbaf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"CS485_584\"):\n",
    "    # Clone the repository if it doesn't already exist\n",
    "    !git clone https://github.com/YoungjoongEmory/CS485_584.git\n",
    "\n",
    "%cd CS485_584/Assignments/HW2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7900f-0471-45e0-b38a-4f3673e6854d",
   "metadata": {
    "id": "b0e7900f-0471-45e0-b38a-4f3673e6854d"
   },
   "source": [
    "### **Step 2**\n",
    "Next, run the cells below to install the necessary libraries and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9508a7-624a-46a7-81e1-3512f48cedb0",
   "metadata": {
    "id": "2c9508a7-624a-46a7-81e1-3512f48cedb0"
   },
   "outputs": [],
   "source": [
    "# Install the necessary dependencies\n",
    "# (restart your runtime session if prompted to, and then re-run this cell)\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354be440-9b19-4d02-9834-45262e22a3ff",
   "metadata": {
    "id": "354be440-9b19-4d02-9834-45262e22a3ff"
   },
   "outputs": [],
   "source": [
    "# Imports the print function from newer versions of python\n",
    "from __future__ import print_function\n",
    "\n",
    "# Numpy is the main package for scientific computing with Python.\n",
    "# This will be one of our most used libraries in this class\n",
    "import numpy as np\n",
    "\n",
    "# The Time library helps us time code runtimes\n",
    "import time\n",
    "\n",
    "# PIL (Pillow) is a useful library for opening, manipulating, and saving images\n",
    "from PIL import Image\n",
    "\n",
    "# skimage (Scikit-Image) is a library for image processing\n",
    "from skimage import io\n",
    "from skimage import filters\n",
    "from skimage.feature import corner_peaks\n",
    "from skimage.io import imread\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "# Matplotlib is a useful plotting library for python\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# This code is to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15.0, 12.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165d3ab-baac-4958-973f-69d2b21df494",
   "metadata": {
    "id": "e165d3ab-baac-4958-973f-69d2b21df494"
   },
   "source": [
    "## Lane Detection\n",
    "\n",
    "In this section we will implement a simple lane detection application using Canny edge detector and Hough transform.\n",
    "\n",
    "The algorithm can broken down into the following steps:\n",
    "1. Detect edges using the Canny edge detector.\n",
    "2. Extract the edges in the region of interest (a triangle covering the bottom corners and the center of the image).\n",
    "3. Run Hough transform to detect lanes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba8be60-469a-4d68-8433-4f921f2391c6",
   "metadata": {
    "id": "7ba8be60-469a-4d68-8433-4f921f2391c6"
   },
   "source": [
    "### 1. Edge detection\n",
    "Lanes on the roads are usually thin and long lines with bright colors. Our edge detection algorithm by itself should be able to find the lanes pretty well. Run the code cell below to load the example image and detect edges from the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c44ac",
   "metadata": {
    "id": "936c44ac"
   },
   "source": [
    "Add your code from HW1 for the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8959b938-752e-4b10-9c1a-492af6d11b1c",
   "metadata": {
    "id": "8959b938-752e-4b10-9c1a-492af6d11b1c"
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(size, sigma):\n",
    "    \"\"\" Implementation of Gaussian Kernel.\n",
    "\n",
    "    This function follows the gaussian kernel formula,\n",
    "    and creates a kernel matrix.\n",
    "\n",
    "    Hints:\n",
    "    - Use np.pi and np.exp to compute pi and exp.\n",
    "\n",
    "    Args:\n",
    "        size: int of the size of output matrix.\n",
    "        sigma: float of sigma to calculate kernel.\n",
    "\n",
    "    Returns:\n",
    "        kernel: numpy array of shape (size, size).\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = np.zeros((size, size))\n",
    "\n",
    "    center = size // 2\n",
    "    yy, xx = np.mgrid[0:size, 0:size]\n",
    "    yy = yy - center\n",
    "    xx = xx - center\n",
    "    coefficient = 1.0 / (2.0 * np.pi * sigma * sigma)\n",
    "    kernel = coefficient * np.exp(-(xx * xx + yy * yy) / (2.0 * sigma * sigma))\n",
    "    sum_kernel = np.sum(kernel)\n",
    "    if sum_kernel != 0:\n",
    "        kernel = kernel / sum_kernel\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def conv(image, kernel):\n",
    "    \"\"\" An implementation of convolution filter.\n",
    "\n",
    "    This function uses element-wise multiplication and np.sum()\n",
    "    to efficiently compute weighted sum of neighborhood at each\n",
    "    pixel.\n",
    "\n",
    "    Args:\n",
    "        image: numpy array of shape (Hi, Wi).\n",
    "        kernel: numpy array of shape (Hk, Wk).\n",
    "\n",
    "    Returns:\n",
    "        out: numpy array of shape (Hi, Wi).\n",
    "    \"\"\"\n",
    "    Hi, Wi = image.shape\n",
    "    Hk, Wk = kernel.shape\n",
    "    out = np.zeros((Hi, Wi))\n",
    "\n",
    "    # For this assignment, we will use edge values to pad the images.\n",
    "    # Zero padding will make derivatives at the image boundary very big,\n",
    "    # whereas we want to ignore the edges at the boundary.\n",
    "    pad_width0 = Hk // 2\n",
    "    pad_width1 = Wk // 2\n",
    "    pad_width = ((pad_width0,pad_width0),(pad_width1,pad_width1))\n",
    "    padded = np.pad(image, pad_width, mode='edge')\n",
    "\n",
    "    # Correlation-style filtering (no kernel flip)\n",
    "    for i in range(Hi):\n",
    "        for j in range(Wi):\n",
    "            window = padded[i:i+Hk, j:j+Wk]\n",
    "            out[i, j] = np.sum(window * kernel)\n",
    "\n",
    "    return out\n",
    "\n",
    "def partial_x(img):\n",
    "    \"\"\" Computes partial x-derivative of input img.\n",
    "\n",
    "    Hints:\n",
    "        - You may use the conv function in defined in this file.\n",
    "\n",
    "    Args:\n",
    "        img: numpy array of shape (H, W).\n",
    "    Returns:\n",
    "        out: x-derivative image.\n",
    "    \"\"\"\n",
    "\n",
    "    sobel_x = np.array([[1, 0, -1],\n",
    "                        [2, 0, -2],\n",
    "                        [1, 0, -1]], dtype=np.float64)\n",
    "    out = conv(img, sobel_x)\n",
    "    return out\n",
    "\n",
    "def partial_y(img):\n",
    "    \"\"\" Computes partial y-derivative of input img.\n",
    "\n",
    "    Hints:\n",
    "        - You may use the conv function in defined in this file.\n",
    "\n",
    "    Args:\n",
    "        img: numpy array of shape (H, W).\n",
    "    Returns:\n",
    "        out: y-derivative image.\n",
    "    \"\"\"\n",
    "\n",
    "    sobel_y = np.array([[1, 2, 1],\n",
    "                        [0, 0, 0],\n",
    "                        [-1, -2, -1]], dtype=np.float64)\n",
    "    out = conv(img, sobel_y)\n",
    "    return out\n",
    "\n",
    "def gradient(img):\n",
    "    \"\"\" Returns gradient magnitude and direction of input img.\n",
    "\n",
    "    Args:\n",
    "        img: Grayscale image. Numpy array of shape (H, W).\n",
    "\n",
    "    Returns:\n",
    "        G: Magnitude of gradient at each pixel in img.\n",
    "            Numpy array of shape (H, W).\n",
    "        theta: Direction(in degrees, 0 <= theta < 360) of gradient\n",
    "            at each pixel in img. Numpy array of shape (H, W).\n",
    "\n",
    "    Hints:\n",
    "        - Use np.sqrt and np.arctan2 to calculate square root and arctan\n",
    "    \"\"\"\n",
    "    Ix = partial_x(img)\n",
    "    Iy = partial_y(img)\n",
    "\n",
    "    G = np.hypot(Ix, Iy)\n",
    "    theta = np.degrees(np.arctan2(Iy, Ix))\n",
    "    theta[theta < 0] += 360.0\n",
    "\n",
    "    return G, theta\n",
    "\n",
    "def non_maximum_suppression(G, theta):\n",
    "    \"\"\" Performs non-maximum suppression.\n",
    "\n",
    "    This function performs non-maximum suppression along the direction\n",
    "    of gradient (theta) on the gradient magnitude image (G).\n",
    "\n",
    "    Args:\n",
    "        G: gradient magnitude image with shape of (H, W).\n",
    "        theta: direction of gradients with shape of (H, W).\n",
    "\n",
    "    Returns:\n",
    "        out: non-maxima suppressed image.\n",
    "    \"\"\"\n",
    "    H, W = G.shape\n",
    "    out = np.zeros((H, W))\n",
    "\n",
    "    # Round the gradient direction to the nearest 45 degrees\n",
    "    theta = np.floor((theta + 22.5) / 45) * 45\n",
    "    theta = (theta % 360.0).astype(np.int32)\n",
    "\n",
    "    for y in range(1, H - 1):\n",
    "        for x in range(1, W - 1):\n",
    "            angle = theta[y, x] % 180  # fold opposite directions\n",
    "            g = G[y, x]\n",
    "\n",
    "            if angle == 0:\n",
    "                g1, g2 = G[y, x - 1], G[y, x + 1]\n",
    "            elif angle == 45:\n",
    "                g1, g2 = G[y - 1, x + 1], G[y + 1, x - 1]\n",
    "            elif angle == 90:\n",
    "                g1, g2 = G[y - 1, x], G[y + 1, x]\n",
    "            else:  # 135 degrees\n",
    "                g1, g2 = G[y - 1, x - 1], G[y + 1, x + 1]\n",
    "\n",
    "            if g >= g1 and g >= g2:\n",
    "                out[y, x] = g\n",
    "\n",
    "    return out\n",
    "\n",
    "def double_thresholding(img, high, low):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img: numpy array of shape (H, W) representing NMS edge response.\n",
    "        high: high threshold(float) for strong edges.\n",
    "        low: low threshold(float) for weak edges.\n",
    "\n",
    "    Returns:\n",
    "        strong_edges: Boolean array representing strong edges.\n",
    "            Strong edeges are the pixels with the values greater than\n",
    "            the higher threshold.\n",
    "        weak_edges: Boolean array representing weak edges.\n",
    "            Weak edges are the pixels with the values smaller or equal to the\n",
    "            higher threshold and greater than the lower threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    strong_edges = img >= high\n",
    "    weak_edges = (img <= high) & (img > low)\n",
    "\n",
    "    return strong_edges, weak_edges\n",
    "\n",
    "def link_edges(strong_edges, weak_edges):\n",
    "    \"\"\" Find weak edges connected to strong edges and link them.\n",
    "\n",
    "    Iterate over each pixel in strong_edges and perform breadth first\n",
    "    search across the connected pixels in weak_edges to link them.\n",
    "    Here we consider a pixel (a, b) is connected to a pixel (c, d)\n",
    "    if (a, b) is one of the eight neighboring pixels of (c, d).\n",
    "\n",
    "    Args:\n",
    "        strong_edges: binary image of shape (H, W).\n",
    "        weak_edges: binary image of shape (H, W).\n",
    "\n",
    "    Returns:\n",
    "        edges: numpy boolean array of shape(H, W).\n",
    "    \"\"\"\n",
    "\n",
    "    H, W = strong_edges.shape\n",
    "    indices = np.stack(np.nonzero(strong_edges)).T\n",
    "    edges = np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    # Make new instances of arguments to leave the original\n",
    "    # references intact\n",
    "    weak_edges = np.copy(weak_edges)\n",
    "    edges = np.copy(strong_edges)\n",
    "\n",
    "    # Stack-based BFS to link weak edges connected to strong ones\n",
    "    stack = [tuple(idx) for idx in indices]\n",
    "    while stack:\n",
    "        y, x = stack.pop()\n",
    "        for ny, nx in get_neighbors(y, x, H, W):\n",
    "            if weak_edges[ny, nx] and not edges[ny, nx]:\n",
    "                edges[ny, nx] = True\n",
    "                weak_edges[ny, nx] = False\n",
    "                stack.append((ny, nx))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def get_neighbors(y, x, H, W):\n",
    "    \"\"\" Return indices of valid neighbors of (y, x).\n",
    "\n",
    "    Return indices of all the valid neighbors of (y, x) in an array of\n",
    "    shape (H, W). An index (i, j) of a valid neighbor should satisfy\n",
    "    the following:\n",
    "        1. i >= 0 and i < H\n",
    "        2. j >= 0 and j < W\n",
    "        3. (i, j) != (y, x)\n",
    "\n",
    "    Args:\n",
    "        y, x: location of the pixel.\n",
    "        H, W: size of the image.\n",
    "    Returns:\n",
    "        neighbors: list of indices of neighboring pixels [(i, j)].\n",
    "    \"\"\"\n",
    "    neighbors = []\n",
    "\n",
    "    for i in (y-1, y, y+1):\n",
    "        for j in (x-1, x, x+1):\n",
    "            if i >= 0 and i < H and j >= 0 and j < W:\n",
    "                if (i == y and j == x):\n",
    "                    continue\n",
    "                neighbors.append((i, j))\n",
    "\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552454da-bdd9-45d0-9442-8f3782c339e1",
   "metadata": {
    "id": "552454da-bdd9-45d0-9442-8f3782c339e1"
   },
   "outputs": [],
   "source": [
    "def canny(img, kernel_size=5, sigma=1.4, high=20, low=15):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img: binary image of shape (H, W).\n",
    "        kernel_size: int of size for kernel matrix.\n",
    "        sigma: float for calculating kernel.\n",
    "        high: high threshold for strong edges.\n",
    "        low: low threashold for weak edges.\n",
    "    Returns:\n",
    "        edge: numpy array of shape(H, W).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Smoothing\n",
    "    blurred_img = conv(img, gaussian_kernel(kernel_size, sigma))\n",
    "    # 2. Finding gradients\n",
    "    G, theta = gradient(blurred_img)\n",
    "    # 3. Non-maximum suppression\n",
    "    nms = non_maximum_suppression(G, theta)\n",
    "    # 4. Double thresholding\n",
    "    strong_edges, weak_edges = double_thresholding(nms, high, low)\n",
    "    # 5. Edge tracking\n",
    "    edge = link_edges(strong_edges, weak_edges)\n",
    "\n",
    "    return edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4bb5d-d4e7-4f1d-962f-2aa3ad0c31c4",
   "metadata": {
    "id": "61f4bb5d-d4e7-4f1d-962f-2aa3ad0c31c4"
   },
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = io.imread('road.jpg', as_gray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31a825-be55-4893-a91f-c2d04c13c992",
   "metadata": {
    "id": "ba31a825-be55-4893-a91f-c2d04c13c992"
   },
   "outputs": [],
   "source": [
    "# Run Canny edge detector\n",
    "edges = canny(img, kernel_size=5, sigma=1.4, high=0.03, low=0.02)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Input Image')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.title('Edges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04f55b7-a260-45de-8799-e8160df4256d",
   "metadata": {
    "id": "c04f55b7-a260-45de-8799-e8160df4256d"
   },
   "source": [
    "### 2. Extracting region of interest (ROI)\n",
    "We can see that the Canny edge detector could find the edges of the lanes. However, we can also see that there are edges of other objects that we are not interested in. Given the position and orientation of the camera, we know that the lanes will be located in the lower half of the image. The code below defines a binary mask for the ROI and extract the edges within the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042a402-5491-41e9-8b0c-7bc81c1bd42f",
   "metadata": {
    "id": "6042a402-5491-41e9-8b0c-7bc81c1bd42f"
   },
   "outputs": [],
   "source": [
    "H, W = img.shape\n",
    "\n",
    "# Generate mask for ROI (Region of Interest)\n",
    "mask = np.zeros((H, W))\n",
    "for i in range(H):\n",
    "    for j in range(W):\n",
    "        if i > (H / W) * j and i > -(H / W) * j + H:\n",
    "            mask[i, j] = 1\n",
    "\n",
    "# Extract edges in ROI\n",
    "roi = edges * mask\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(mask)\n",
    "plt.title('Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(roi)\n",
    "plt.title('Edges in ROI')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba41f9-14a2-4d1b-9c60-33f3414566d2",
   "metadata": {
    "id": "9dba41f9-14a2-4d1b-9c60-33f3414566d2"
   },
   "source": [
    "### 3. Fitting lines using Hough transform (15 points)\n",
    "The output from the edge detector is still a collection of connected points. However, it would be more natural to represent a lane as a line parameterized as $y = ax + b$, with a slope $a$ and y-intercept $b$. We will use Hough transform to find parameterized lines that represent the detected edges.\n",
    "\n",
    "In general, a straight line $y = ax + b$ can be represented as a point $(a, b)$ in the parameter space. This is the parameterization we often use when introducing the Hough transform.  However, this cannot represent vertical lines as the slope parameter will be unbounded. Alternatively, we parameterize a line using $\\theta\\in{[-\\pi, \\pi]}$ and $\\rho\\in{\\mathbb{R}}$ as follows:\n",
    "\n",
    "$$\n",
    "\\rho = x\\cdot{cos\\theta} + y\\cdot{sin\\theta}\n",
    "$$\n",
    "\n",
    "Using this parameterization, we can map every point in $xy$-space to a sine-like line in $\\theta\\rho$-space (or Hough space). We then accumulate the parameterized points in the Hough space and choose points (in Hough space) with highest accumulated values. A point in Hough space then can be transformed back into a line in $xy$-space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90e4b3-a7a5-46fa-b2ca-c728a28c0fbd",
   "metadata": {
    "id": "1f90e4b3-a7a5-46fa-b2ca-c728a28c0fbd"
   },
   "outputs": [],
   "source": [
    "def hough_transform(img):\n",
    "    \"\"\" Transform points in the input image into Hough space.\n",
    "\n",
    "    Use the parameterization:\n",
    "        rho = x * cos(theta) + y * sin(theta)\n",
    "    to transform a point (x,y) to a sine-like function in Hough space.\n",
    "\n",
    "    Args:\n",
    "        img: binary image of shape (H, W).\n",
    "\n",
    "    Returns:\n",
    "        accumulator: numpy array of shape (m, n).\n",
    "        rhos: numpy array of shape (m, ).\n",
    "        thetas: numpy array of shape (n, ).\n",
    "    \"\"\"\n",
    "    # Set rho and theta ranges\n",
    "    W, H = img.shape\n",
    "    diag_len = int(np.ceil(np.sqrt(W * W + H * H)))\n",
    "    rhos = np.linspace(-diag_len, diag_len, diag_len * 2 + 1)\n",
    "    thetas = np.deg2rad(np.arange(-90.0, 90.0))\n",
    "\n",
    "    # Cache some reusable values\n",
    "    cos_t = np.cos(thetas)\n",
    "    sin_t = np.sin(thetas)\n",
    "    num_thetas = len(thetas)\n",
    "\n",
    "    # Initialize accumulator in the Hough space\n",
    "    accumulator = np.zeros((2 * diag_len + 1, num_thetas), dtype=np.uint64)\n",
    "    ys, xs = np.nonzero(img)\n",
    "\n",
    "    # Transform each point (x, y) in image\n",
    "    # Find rho corresponding to values in thetas\n",
    "    # and increment the accumulator in the corresponding coordiate.\n",
    "    for y, x in zip(ys, xs):\n",
    "        for t_idx in range(num_thetas):\n",
    "            rho = x * cos_t[t_idx] + y * sin_t[t_idx]\n",
    "            r_idx = int(round(rho)) + diag_len\n",
    "            if 0 <= r_idx < accumulator.shape[0]:\n",
    "                accumulator[r_idx, t_idx] += 1\n",
    "\n",
    "    return accumulator, rhos, thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4cc50-cee9-4ad5-8c9c-aae9fd2ce83b",
   "metadata": {
    "id": "28c4cc50-cee9-4ad5-8c9c-aae9fd2ce83b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform Hough transform on the ROI\n",
    "acc, rhos, thetas = hough_transform(roi)\n",
    "\n",
    "# Coordinates for right lane\n",
    "xs_right = []\n",
    "ys_right = []\n",
    "\n",
    "# Coordinates for left lane\n",
    "xs_left = []\n",
    "ys_left = []\n",
    "\n",
    "for i in range(20):\n",
    "    idx = np.argmax(acc)\n",
    "    r_idx = idx // acc.shape[1]\n",
    "    t_idx = idx % acc.shape[1]\n",
    "    acc[r_idx, t_idx] = 0 # Zero out the max value in accumulator\n",
    "\n",
    "    rho = rhos[r_idx]\n",
    "    theta = thetas[t_idx]\n",
    "\n",
    "    # Transform a point in Hough space to a line in xy-space.\n",
    "    a = - (np.cos(theta)/np.sin(theta)) # slope of the line\n",
    "    b = (rho/np.sin(theta)) # y-intersect of the line\n",
    "\n",
    "    # Break if both right and left lanes are detected\n",
    "    if xs_right and xs_left:\n",
    "        break\n",
    "\n",
    "    if a < 0: # Left lane\n",
    "        if xs_left:\n",
    "            continue\n",
    "        xs = xs_left\n",
    "        ys = ys_left\n",
    "    else: # Right Lane\n",
    "        if xs_right:\n",
    "            continue\n",
    "        xs = xs_right\n",
    "        ys = ys_right\n",
    "\n",
    "    for x in range(img.shape[1]):\n",
    "        y = a * x + b\n",
    "        if y > img.shape[0] * 0.6 and y < img.shape[0]:\n",
    "            xs.append(x)\n",
    "            ys.append(int(round(y)))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.plot(xs_left, ys_left, linewidth=5.0)\n",
    "plt.plot(xs_right, ys_right, linewidth=5.0)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
